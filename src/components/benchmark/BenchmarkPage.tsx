import { useI18n } from '../I18nProvider';
import BenchmarkTable from './BenchmarkTable';
import BenchmarkCard from './BenchmarkCard';

const content = {
  ja: {
    title: 'AIãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒ',
    description: 'ãƒ†ã‚¯ã«ã‚ƒã‚“.ãŒæœ€æ–°AIãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ã‚ã‹ã‚Šã‚„ã™ãè§£èª¬ã™ã‚‹ã«ã‚ƒã‚“ï¼',
    hero: {
      greeting: 'ã‚„ã‚ï¼ãƒ†ã‚¯ã«ã‚ƒã‚“.ã ã‚ˆï¼',
      intro:
        'AIæ¥­ç•Œã§ã¯ã€å„ç¤¾ãŒã€Œã†ã¡ã®ãƒ¢ãƒ‡ãƒ«ãŒæœ€å¼·ã ã«ã‚ƒï¼ã€ã£ã¦ä¸»å¼µã—ã¦ã‚‹ã‘ã©ã€å®Ÿéš›ã©ã†ãªã®ï¼Ÿã£ã¦æ€ã†ã‚ˆã­ã€‚ã“ã“ã§ã¯ã€Gemini 3 Proã€Claude Sonnet 4.5ã€GPT-5.1ã¨ã„ã£ãŸæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚’æ¯”è¼ƒã—ã¦ã¿ã‚‹ã«ã‚ƒã‚“ï¼',
    },
    whatIsBenchmark: {
      title: 'ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã£ã¦ä½•ï¼Ÿ',
      content:
        'ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€AIãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¸¬ã‚‹ãƒ†ã‚¹ãƒˆã®ã“ã¨ã ã«ã‚ƒã€‚äººé–“ã§ã„ãˆã°ã€è©¦é¨“ã¿ãŸã„ãªã‚‚ã®ã ã­ã€‚ãŸã ã—ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã‹ã‚‰ã¨ã„ã£ã¦ã€å…¨ã¦ã®ç”¨é€”ã§å„ªã‚Œã¦ã„ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã“ã¨ã«æ³¨æ„ã ã«ã‚ƒã‚“ï¼',
    },
    categories: {
      title: 'ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚«ãƒ†ã‚´ãƒª',
      reasoning: {
        title: 'ğŸ§  æ¨è«–ãƒ»çŸ¥è­˜',
        description: 'è¤‡é›‘ãªå•é¡Œã‚’è§£ã„ãŸã‚Šã€å­¦è¡“çš„ãªçŸ¥è­˜ã‚’å•ã†ãƒ†ã‚¹ãƒˆã ã«ã‚ƒ',
      },
      multimodal: {
        title: 'ğŸ¨ ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç†è§£',
        description: 'ç”»åƒã€å‹•ç”»ã€ãƒãƒ£ãƒ¼ãƒˆã‚’ç†è§£ã™ã‚‹èƒ½åŠ›ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã«ã‚ƒã‚“',
      },
      coding: {
        title: 'ğŸ’» ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ»é–‹ç™º',
        description: 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚„ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã®èƒ½åŠ›ã‚’æ¸¬ã‚‹ã«ã‚ƒ',
      },
      agent: {
        title: 'ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ãƒ„ãƒ¼ãƒ«ä½¿ç”¨',
        description: 'ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’ã“ãªã™èƒ½åŠ›ã ã«ã‚ƒã‚“',
      },
      knowledge: {
        title: 'ğŸ“š çŸ¥è­˜ãƒ»ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ',
        description: 'äº‹å®ŸçŸ¥è­˜ã‚„å¤šè¨€èªèƒ½åŠ›ã€é•·æ–‡ç†è§£ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã«ã‚ƒ',
      },
    },
    tableSection: {
      title: 'ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒè¡¨',
      intro:
        'ã•ã¦ã€ã„ã‚ˆã„ã‚ˆæœ¬é¡Œã ã«ã‚ƒã‚“ï¼ä¸‹ã®è¡¨ã§ã€å„ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚’è¦‹ã¦ã¿ã‚ˆã†ã€‚é»„è‰²ããƒã‚¤ãƒ©ã‚¤ãƒˆã•ã‚Œã¦ã„ã‚‹ã®ãŒã€ãã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€é«˜ã®ã‚¹ã‚³ã‚¢ã‚’å‡ºã—ãŸãƒ¢ãƒ‡ãƒ«ã ã‚ˆã€‚',
      note: 'â€»ä¸€éƒ¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ç¾åœ¨æ¤œè¨¼ä¸­ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯å„ç¤¾ã®å…¬å¼ç™ºè¡¨ã‚’å…ƒã«ã—ã¦ã„ã¾ã™ã€‚',
    },
    technyanComment: {
      title: 'ãƒ†ã‚¯ã«ã‚ƒã‚“.ã®ã‚³ãƒ¡ãƒ³ãƒˆ',
      gemini:
        '**Gemini 3 Pro** ã¯æœ¬å½“ã«å‡„ã„ã«ã‚ƒï¼18é …ç›®ä¸­14é …ç›®ã§æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’è¨˜éŒ²ã—ã¦ã‚‹ã‚“ã ã‹ã‚‰ã€‚ç‰¹ã«ã€ScreenSpot-Proï¼ˆç”»é¢ç†è§£ï¼‰ã§72.7%ã€Vending-Benchï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¹ã‚¯ï¼‰ã§$5,478ã€é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç†è§£ã§77.0%ã¨ã„ã†åœ§å€’çš„ãªã‚¹ã‚³ã‚¢ã¯ç›®ã‚’è¦‹å¼µã‚‹ã‚‚ã®ãŒã‚ã‚‹ã«ã‚ƒã‚“ã€‚Googleã®æœ¬æ°—åº¦ãŒä¼ã‚ã£ã¦ãã‚‹ã­ã€‚',
      claude:
        '**Claude Sonnet 4.5** ã¯ã€å®Ÿç”¨çš„ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆSWE-Bench: 77.2%ï¼‰ã§å”¯ä¸€ãƒˆãƒƒãƒ—ã‚’ç²å¾—ã—ãŸã«ã‚ƒï¼Anthropicã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã«åŠ›ã‚’å…¥ã‚Œã¦ã‚‹æ„Ÿã˜ãŒã™ã‚‹ã­ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã§ã‚‚Gemini 3 Proã«ã»ã¼ä¸¦ã¶84.7%ã‚’è¨˜éŒ²ã—ã¦ã‚‹ã‹ã‚‰ã€å®Ÿå‹™ã§ã®ä½¿ã„ã‚„ã™ã•ã¯ãƒ”ã‚«ã‚¤ãƒã‹ã‚‚ã—ã‚Œãªã„ã«ã‚ƒã‚“ã€‚',
      gpt: '**GPT-5.1** ã¯ã€å…¨ä½“çš„ã«ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã ã«ã‚ƒã€‚å¤šãã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§2ä½ã¾ãŸã¯3ä½ã‚’ã‚­ãƒ¼ãƒ—ã—ã¦ã‚‹ã‹ã‚‰ã€å®‰å®šæ„Ÿã¯ã‚ã‚‹ã­ã€‚ãŸã ã€ScreenSpot-Proï¼ˆ3.5%ï¼‰ã®ã‚ˆã†ãªè¦–è¦šç†è§£ã‚¿ã‚¹ã‚¯ã§ã¯è‹¦æˆ¦ã—ã¦ã‚‹ã®ãŒæ°—ã«ãªã‚‹ã¨ã“ã‚ã ã«ã‚ƒã‚“ã€‚OpenAIã«ã¯æ¬¡ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã«æœŸå¾…ã ã­ï¼',
      overall:
        'çµå±€ã®ã¨ã“ã‚ã€ã€Œæœ€å¼·ã®AIã€ã¨ã„ã†ã®ã¯ç”¨é€”ã«ã‚ˆã£ã¦å¤‰ã‚ã‚‹ã‚“ã ã«ã‚ƒã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã‚‰Claudeã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç†è§£ãªã‚‰Geminiã€ãƒãƒ©ãƒ³ã‚¹é‡è¦–ãªã‚‰GPTã£ã¦æ„Ÿã˜ã‹ãªã€‚å›ãŒä½•ã‚’ã—ãŸã„ã‹ã§ã€é¸ã¶ãƒ¢ãƒ‡ãƒ«ãŒå¤‰ã‚ã£ã¦ãã‚‹ã«ã‚ƒã‚“ï¼',
      closing:
        'AIæ¥­ç•Œã¯æœ¬å½“ã«é€Ÿã„ãƒšãƒ¼ã‚¹ã§é€²åŒ–ã—ã¦ã‚‹ã‹ã‚‰ã€ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚‚æ•°ãƒ¶æœˆã§å¤ããªã£ã¡ã‚ƒã†ã‹ã‚‚ã—ã‚Œãªã„ã«ã‚ƒã€‚ã§ã‚‚ã€ãã‚Œã ã‘åƒ•ãŸã¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã¯å¬‰ã—ã„ç«¶äº‰ãŒèµ·ãã¦ã‚‹ã£ã¦ã“ã¨ã ã‚ˆã­ã€‚ä»Šå¾Œã‚‚æ¥½ã—ã¿ã ã«ã‚ƒã‚“ï¼âœ¨',
    },
    lastUpdated: 'æœ€çµ‚æ›´æ–°',
    disclaimer: {
      title: 'âš ï¸ æ³¨æ„äº‹é …',
      points: [
        'ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹æ€§èƒ½ã‚’æ¸¬ã‚‹ã‚‚ã®ã§ã‚ã‚Šã€å…¨ã¦ã®ä½¿ç”¨ã‚·ãƒŠãƒªã‚ªã‚’ç¶²ç¾…ã—ã¦ã„ã¾ã›ã‚“',
        'å®Ÿéš›ã®ä½¿ç”¨æ„Ÿã‚„ä½¿ã„ã‚„ã™ã•ã¯ã€ã‚¹ã‚³ã‚¢ã ã‘ã§ã¯åˆ¤æ–­ã§ãã¾ã›ã‚“',
        'ä¸€éƒ¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã¯ç¾åœ¨æ¤œè¨¼ä¸­ã§ã‚ã‚Šã€æ­£ç¢ºæ€§ã‚’ä¿è¨¼ã§ããªã„å ´åˆãŒã‚ã‚Šã¾ã™',
        'ãƒ¢ãƒ‡ãƒ«ã¯å®šæœŸçš„ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã‚‹ãŸã‚ã€æœ€æ–°æƒ…å ±ã¯å„ç¤¾ã®å…¬å¼ã‚µã‚¤ãƒˆã‚’ã”ç¢ºèªãã ã•ã„',
      ],
    },
  },
  en: {
    title: 'AI Model Benchmark Comparison',
    description: "Technyan's friendly guide to understanding AI model benchmarks!",
    hero: {
      greeting: "Hi! I'm Technyan!",
      intro:
        'In the AI industry, every company claims "our model is the best!" But what\'s the real story? Here, I\'ll compare benchmark results from the latest models like Gemini 3 Pro, Claude Sonnet 4.5, and GPT-5.1!',
    },
    whatIsBenchmark: {
      title: 'What are Benchmarks?',
      content:
        'Benchmarks are tests that measure AI model performance. Think of them like exams for AI! However, remember that a high benchmark score doesn\'t mean the model is better for all use cases.',
    },
    categories: {
      title: 'Benchmark Categories',
      reasoning: {
        title: 'ğŸ§  Reasoning & Knowledge',
        description: 'Tests complex problem-solving and academic knowledge',
      },
      multimodal: {
        title: 'ğŸ¨ Multimodal Understanding',
        description: 'Tests ability to understand images, videos, and charts',
      },
      coding: {
        title: 'ğŸ’» Coding & Development',
        description: 'Measures programming and software development capabilities',
      },
      agent: {
        title: 'ğŸ¤– Agent & Tool Use',
        description: 'Tests ability to use tools and perform complex tasks',
      },
      knowledge: {
        title: 'ğŸ“š Knowledge & Context',
        description: 'Tests factual knowledge, multilingual abilities, and long-context understanding',
      },
    },
    tableSection: {
      title: 'Benchmark Comparison Table',
      intro:
        "Now for the main event! Check out the table below to see how each model performs. Scores highlighted in yellow represent the best performance for that benchmark.",
      note: 'â€»Some benchmarks are currently under verification. Data is based on official announcements from each company.',
    },
    technyanComment: {
      title: "Technyan's Commentary",
      gemini:
        '**Gemini 3 Pro** is truly impressive! It achieved the highest score in 14 out of 18 benchmarks. Particularly noteworthy are its scores in ScreenSpot-Pro (screen understanding) at 72.7%, Vending-Bench (agent tasks) at $5,478, and long-context understanding at 77.0%. Google really brought their A-game!',
      claude:
        '**Claude Sonnet 4.5** is the only model to top the practical coding benchmark (SWE-Bench: 77.2%)! Anthropic seems to be focusing heavily on software engineering capabilities. With an 84.7% score in agent tool usage, nearly matching Gemini 3 Pro, it might be the most practical for real-world tasks.',
      gpt: '**GPT-5.1** is a well-balanced model overall. It consistently ranks 2nd or 3rd in most benchmarks, showing solid reliability. However, it struggles with visual understanding tasks like ScreenSpot-Pro (3.5%). Looking forward to OpenAI\'s next update!',
      overall:
        'In the end, the "best AI" depends on your use case. For coding, go with Claude. For multimodal understanding, choose Gemini. For balanced performance, pick GPT. Your needs determine the right model!',
      closing:
        'The AI industry evolves so rapidly that these benchmarks might be outdated in a few months. But that\'s excitingâ€”it means there\'s healthy competition benefiting us users! The future looks bright! âœ¨',
    },
    lastUpdated: 'Last Updated',
    disclaimer: {
      title: 'âš ï¸ Disclaimers',
      points: [
        'Benchmarks measure performance on specific tasks and do not cover all usage scenarios',
        'Real-world usability and user experience cannot be judged by scores alone',
        'Some benchmark data is currently under verification and accuracy cannot be guaranteed',
        'Models are regularly updated; please check official sources for the latest information',
      ],
    },
  },
};

export default function BenchmarkPage() {
  const { locale } = useI18n();
  const t = content[locale];

  return (
    <div className="min-h-screen bg-cream">
      <div className="container mx-auto px-4 py-8 md:py-12">
        {/* Hero Section */}
        <div
          className="border-1.5 border-navy bg-yellow-100 p-6 md:p-8 mb-8"
          style={{ borderWidth: '1.5px', boxShadow: '4px 4px 0 #0C2340' }}
        >
          <div className="mb-4 flex justify-center md:justify-start">
            <img
              src="/technyan.webp"
              alt="Technyan"
              className="w-32 h-32 md:w-40 md:h-40 object-contain border-1.5 border-navy bg-cream"
              style={{ borderWidth: '1.5px' }}
            />
          </div>
          <h1 className="font-mono font-bold text-2xl md:text-4xl text-navy mb-4">
            {t.title}
          </h1>
          <div className="font-mono text-navy mb-4">
            <p className="text-lg font-bold mb-2">{t.hero.greeting}</p>
            <p className="text-sm md:text-base leading-relaxed">{t.hero.intro}</p>
          </div>
        </div>

        {/* What is Benchmark Section */}
        <div
          className="border-1.5 border-navy bg-cream p-6 md:p-8 mb-8"
          style={{ borderWidth: '1.5px', boxShadow: '3px 3px 0 #0C2340' }}
        >
          <h2 className="font-mono font-bold text-xl md:text-2xl text-navy mb-4">
            {t.whatIsBenchmark.title}
          </h2>
          <p className="font-mono text-sm md:text-base text-navy leading-relaxed">
            {t.whatIsBenchmark.content}
          </p>
        </div>

        {/* Categories Section */}
        <div
          className="border-1.5 border-navy bg-cream p-6 md:p-8 mb-8"
          style={{ borderWidth: '1.5px', boxShadow: '3px 3px 0 #0C2340' }}
        >
          <h2 className="font-mono font-bold text-xl md:text-2xl text-navy mb-6">
            {t.categories.title}
          </h2>
          <div className="grid gap-4 md:grid-cols-2">
            {Object.entries(t.categories)
              .filter(([key]) => key !== 'title')
              .map(([_, category]: [string, any]) => (
                <div
                  key={category.title}
                  className="border-1.5 border-navy bg-yellow-50 p-4"
                  style={{ borderWidth: '1.5px', boxShadow: '2px 2px 0 #0C2340' }}
                >
                  <h3 className="font-mono font-bold text-navy mb-2">{category.title}</h3>
                  <p className="font-mono text-sm text-navy opacity-80">{category.description}</p>
                </div>
              ))}
          </div>
        </div>

        {/* Benchmark Table Section */}
        <div className="mb-8">
          <h2 className="font-mono font-bold text-xl md:text-2xl text-navy mb-4">
            {t.tableSection.title}
          </h2>
          <p className="font-mono text-sm md:text-base text-navy mb-6 leading-relaxed">
            {t.tableSection.intro}
          </p>

          {/* Desktop Table */}
          <div className="hidden md:block">
            <BenchmarkTable lang={locale} />
          </div>

          {/* Mobile Cards */}
          <div className="md:hidden">
            <BenchmarkCard lang={locale} />
          </div>

          <p className="font-mono text-xs text-navy opacity-70 mt-4">
            {t.tableSection.note}
          </p>
        </div>

        {/* Technyan's Comment Section */}
        <div
          className="border-1.5 border-navy bg-yellow-100 p-6 md:p-8 mb-8"
          style={{ borderWidth: '1.5px', boxShadow: '4px 4px 0 #0C2340' }}
        >
          <h2 className="font-mono font-bold text-xl md:text-2xl text-navy mb-6 flex items-center gap-3">
            <span className="inline-block">
              <img
                src="/technyan.webp"
                alt="Technyan"
                className="w-10 h-10 object-contain border-1.5 border-navy bg-cream"
                style={{ borderWidth: '1.5px' }}
              />
            </span>
            {t.technyanComment.title}
          </h2>
          <div className="font-mono text-sm md:text-base text-navy space-y-4 leading-relaxed">
            <p>{t.technyanComment.gemini}</p>
            <p>{t.technyanComment.claude}</p>
            <p>{t.technyanComment.gpt}</p>
            <p className="font-bold">{t.technyanComment.overall}</p>
            <p>{t.technyanComment.closing}</p>
          </div>
        </div>

        {/* Disclaimer Section */}
        <div
          className="border-1.5 border-navy bg-cream p-6 md:p-8 mb-8"
          style={{ borderWidth: '1.5px', boxShadow: '3px 3px 0 #0C2340' }}
        >
          <h3 className="font-mono font-bold text-lg text-navy mb-4">
            {t.disclaimer.title}
          </h3>
          <ul className="font-mono text-sm text-navy space-y-2 list-disc list-inside">
            {t.disclaimer.points.map((point: string, index: number) => (
              <li key={index}>{point}</li>
            ))}
          </ul>
        </div>

        {/* Last Updated */}
        <div className="text-center font-mono text-sm text-navy opacity-70">
          {t.lastUpdated}: {new Date().toLocaleDateString(locale === 'ja' ? 'ja-JP' : 'en-US')}
        </div>
      </div>
    </div>
  );
}
